{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vítejte u třetího projektu do SUI! V tomto projektu si procvičíte trénování jednoduchých neuronových sítí. Dost jednoduchých na to, abyste pro výpočty nepotřebovali grafickou kartu. Na druhé straně, dost složitých na to, abychom Vás již netrápili implementaci v holém NumPy. Vaším nultým úkolem bude nainstalovat si PyTorch, na [domovské stránce projektu](https://pytorch.org/) si můžete nechat vygenerovat instalační příkaz pro Vaše potřeby.\n",
    "\n",
    "Odevzdejte prosím dvojici souborů: Vyrenderované PDF a vyexportovaný Python (File -> Download as). Obojí **pojmenujte loginem vedoucího týmu**. U PDF si pohlídejte, že Vám nemizí kód za okrajem stránky.\n",
    "\n",
    "V jednotlivých buňkách s úkoly (což nejsou všechny) nahrazujte `pass` a `None` vlastním kódem.\n",
    "\n",
    "V průběhu řešení se vždy vyvarujte cyklení po jednotlivých datech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Celý tento projekt bude věnován regresi, tj. odhadu spojité výstupní veličiny.\n",
    "V první části projektu budete pracovat s následující funkcí:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return torch.cos(x) + x/2\n",
    "\n",
    "xs = np.linspace(-5, 5, 50)\n",
    "\n",
    "plt.plot(xs, func(torch.tensor(xs)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaším prvním úkolem bude pomocí PyTorche vypočítat hodnoty derivace této funkce na rozsahu <-5, 5>.\n",
    "Vytvořte si tensor `x`ů a řekněte PyTorchi, že budete vzhledem k němu chtít spočítat gradienty (defaultně se to u `Tensor`u nepředpokládá).\n",
    "Pomocí back-propagace je pak vypočítejte.\n",
    "PyTorch umí backpropagovat jenom skalár, najděte tedy způsob, jak agregovat všechny výstupy funkce tak, aby složky gradientu agregované hodnoty byly hodnotami derivace funkce `func` v jednotlivých `x`ech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = None\n",
    "fs = func(xs)\n",
    "pass\n",
    "\n",
    "plt.plot(xs.detach(), fs.detach(), label=\"f(x)\")\n",
    "plt.plot(xs.detach(), xs.grad, label=\"f'(x)\")\n",
    "plt.plot(xs.detach(),  1 * np.ones(xs.shape[0]), color='gray', linestyle='--')\n",
    "plt.plot(xs.detach(), -1 * np.ones(xs.shape[0]), color='gray', linestyle='--')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dále budete hledat lokální minimum této funkce.\n",
    "Naimplementujte funkci `tangent_minimum`, která -- v blízké podobnosti metodě tečen -- nalezne řešení, resp. vrátí posloupnost jednotlivých bodů, jimiž při hledání minima prošla.\n",
    "Jejími vstupy jsou: \n",
    "* `function` -- PyTorch-kompatibilní funkce\n",
    "* `x0` -- počáteční bod\n",
    "* `nb_steps` -- zadaný počet kroků, který má být proveden. Ve výstupu tedy bude `nb_steps + 1` položek (vč. `x0`)\n",
    "\n",
    "Reálně implementujte gradient descent, tedy iterativně vypočítejte hodnotu gradientu (derivace) v aktuálním bodě řešení a odečtěte ji od onoho bodu.\n",
    "Neuvažujte žádnou learning rate (resp. rovnou jedné) a nepoužívejte žádné vestavěné optimalizátory z PyTorche.\n",
    "\n",
    "Zbylý kód v buňce pak funkci zavolá a vykreslí, jak postupovala."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tangent_minimum(function, x0, nb_steps):\n",
    "    pass\n",
    "\n",
    "x0 = torch.tensor([0.0], requires_grad=True)\n",
    "updates = tangent_minimum(func, x0, 6)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(xs.detach(),  0 * np.ones(xs.shape[0]), color='gray', linestyle='--')\n",
    "plt.plot(xs.detach(), func(xs).detach(), 'b')\n",
    "plt.plot(updates, func(torch.tensor(updates)).detach(), 'r', marker='o')\n",
    "\n",
    "for i, (x, y) in enumerate(zip(updates, func(torch.tensor(updates)).detach())):\n",
    "    plt.annotate(f'{i}', (x, y), xytext=(x-0.2, y+0.2))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelování polynomů\n",
    "\n",
    "V následujících několika buňkách budete usilovat o modelování této křivky pomocí polynomů.\n",
    "Prvním krokem bude implementace třídy `LinearRegression`, která bude implementovat ... lineární regresi, pomocí jediného objektu třídy... `torch.nn.Linear`!\n",
    "Po vytvoření objektu `torch.nn.Linear` sáhněte do jeho útrob a nastavte na nulu bias a všechny váhy kromě nulté -- tu nastavte na jednu polovinu.\n",
    "Tím získáte model $y = \\frac{x}{2}$, který pro nadcházející úlohu není úplně mimo, a nebudete se tak trápit s dramatickým dynamickým rozsahem loss.\n",
    "\n",
    "Nechť `LinearRegression` dědí od `torch.nn.Module`, výpočet tedy specifikujte v metodě `forward()`.\n",
    "Při výpočtu zařiďte, aby byl výstup ve tvaru `[N]`, nikoliv `[N, 1]`; zároveň to ale nepřežeňte a pro jediný vstup vracejte stále vektor o rozměru `[1]` a ne jen skalár.\n",
    "Dále naimplementujte metodu `l2_norm()`, která vrací eukleidovskou velikost všech parametrů modelu dohromady, jakoby tvořily jediný vektor.\n",
    "Může se vám hodit `torch.nn.Module.parameters()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        pass\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return None\n",
    "    \n",
    "    def l2_norm(self):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naimplementujte funkci pro trénování modelu takového modelu.\n",
    "Funkce přijímá:\n",
    "* `model` -- PyTorch-kompatibilní model\n",
    "* `loss_fun` -- funkci, která konzumuje výstupy modelu a cílové hodnoty a model (kvůli regularizaci)\n",
    "* `optimizer` -- PyToch-kompatibilní optimalizátor\n",
    "* `train_X` -- trénovací data ve formátu `[N, F]`\n",
    "* `train_t` -- cílové hodnoty ve formátu `[N]`\n",
    "* `nb_steps` -- počet kroků, které se mají provést\n",
    "\n",
    "Funkce potom vrací průběh trénovací MSE a průběh velikosti parametrů (předpokládejte, že `model` poskytuje `.l2_norm()`).\n",
    "Tedy, dodaná `loss_fun` je použita pouze pro optimalizaci, ale nikde se její hodnoty nelogují.\n",
    "\n",
    "Dále naimplementujte třídu `MSE_with_regression`, jejíž instance budou sloužit jako mean-square-error loss, navíc rozšířená o L2 regularizaci, jejíž sílu určí uživatel při konstrukci parametrem `l2_beta`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_regression_model(model, loss_fun, optimizer, train_X, train_t, nb_steps=100):\n",
    "    mses = []\n",
    "    norms = []\n",
    "    for _ in range(nb_steps):\n",
    "        pass\n",
    "        \n",
    "    return mses, norms\n",
    "\n",
    "class MSE_with_regression:\n",
    "    def __init__(self, l2_beta=0.0):\n",
    "        self.loss = torch.nn.MSELoss()\n",
    "        self.l2_beta = l2_beta\n",
    "    \n",
    "    def __call__(self, y, t, model):\n",
    "        mse = None\n",
    "        l2 = None\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spusťte trénování několikrát pomocí `try_beta` a najděte tři nastavení, která dají po řadě:\n",
    "1. Dobrý odhad.\n",
    "2. Silně potlačený odhad regrese, kde ale bude pořád dobře zřetelný trend růstu\n",
    "3. Extrémně zregularizovaný model, který de facto predikuje konstantu.\n",
    "\n",
    "Omezte se na interval <1e-10, 1e+10>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_result(model, losses, norms):\n",
    "    fig, axs = plt.subplots(ncols=2, figsize=(13, 6))\n",
    "    axs[0].plot(xs.detach(), model(xs.float().unsqueeze(-1)).detach())\n",
    "    axs[0].scatter(data, ts, c='r')\n",
    "\n",
    "    axs[1].plot(losses, 'r-', label='mse')\n",
    "    axs[1].legend(loc=\"upper left\")\n",
    "    axs[1].set_ylim(bottom=0)\n",
    "    ax_2 = axs[1].twinx()\n",
    "    ax_2.plot(norms, 'b-', label='norms')\n",
    "    ax_2.legend(loc=\"upper right\")\n",
    "    ax_2.set_ylim(bottom=0)\n",
    "\n",
    "\n",
    "xs = torch.linspace(-5, 5, steps=100)\n",
    "data = torch.tensor([-4.99, 3.95, -1.5, -0.15, 0, 0.15, 2, 4.9]).unsqueeze(-1)\n",
    "ts = func(data).squeeze(-1).detach()\n",
    "\n",
    "def try_beta(l2_beta):\n",
    "    regr_1 = LinearRegression(1)\n",
    "    opt = torch.optim.Adam(regr_1.parameters(), 3e-2)\n",
    "    losses, norms = train_regression_model(regr_1, MSE_with_regression(l2_beta), opt, data, ts)\n",
    "    plot_training_result(regr_1, losses, norms)\n",
    "\n",
    "try_beta(None)\n",
    "try_beta(None)\n",
    "try_beta(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zde doimplementujte metodu forward pro `PolynomialRegression`.\n",
    "Je potřeba vytvořit rozšířené příznaky a slepit je do jednoho tensoru o tvaru `[N, F]`, který předložíte `self.lin_reg`.\n",
    "Nezapomeňte pak výstup opět omezit na `[N]`.\n",
    "\n",
    "Zbytek buňky Vám model natrénuje v několika různých variantách řádu polynomu a síly regularizace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolynomialRegression1D(torch.nn.Module):\n",
    "    def __init__(self, order):\n",
    "        super().__init__()\n",
    "        self.order = order\n",
    "        self.lin_reg = LinearRegression(order)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        pass\n",
    "        return None\n",
    "        \n",
    "    def l2_norm(self):\n",
    "        return self.lin_reg.l2_norm()            \n",
    "\n",
    "def run_polynomial_regr(order, l2_beta):\n",
    "    model = PolynomialRegression1D(order)\n",
    "\n",
    "    losses, norms = train_regression_model(\n",
    "        model,\n",
    "        MSE_with_regression(l2_beta),\n",
    "        torch.optim.Adam(model.parameters(), 1e-2),\n",
    "        data,\n",
    "        ts,\n",
    "        nb_steps= 50 + int(100*(order-2)**2.5)\n",
    "    )\n",
    "    plot_training_result(model, losses, norms)\n",
    "\n",
    "run_polynomial_regr(3, 1e-3)\n",
    "run_polynomial_regr(3, 1e+2)\n",
    "run_polynomial_regr(7, 1e-1)\n",
    "run_polynomial_regr(7, 1e+3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regrese meteorologických dat\n",
    "V této části budete usilovat o doplnění tlaku vzduchu z dalších meteorologických měření.\n",
    "Nejprve pomocí lineární regrese, následně pomocí jednoduché neuronové sítě.\n",
    "Každopádně více pomocí vestavěných věcí z PyTorche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turany = np.loadtxt('data-chmu/turany.txt', dtype=np.float32)\n",
    "mosnov = np.loadtxt('data-chmu/mosnov.txt', dtype=np.float32)\n",
    "kosetice = np.loadtxt('data-chmu/kosetice.txt', dtype=np.float32)\n",
    "ruzyne = np.loadtxt('data-chmu/ruzyne.txt', dtype=np.float32)\n",
    "pribyslav = np.loadtxt('data-chmu/pribyslav.txt', dtype=np.float32)\n",
    "\n",
    "features = ['teplota průměrná', 'teplota maximální', 'teplota minimální', 'rychlost větru ', 'tlak vzduchu', 'vlhkost vzduchu', 'úhrn srážek', 'celková výška sněhu', 'sluneční svit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V prvním kroce doplňte definici `MeteoDataset`u o `__getitem__()` a `__len__()`, tak jak se to očekává u objektů třídy `torch.utils.data.Dataset`.\n",
    "Navíc přidejte vlastnost (`@property`) `in_dim`, která říká, kolik příznaků má každé jedno dato v datasetu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeteoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, target_feature):\n",
    "        self.ts = data[target_feature]\n",
    "        self.xs = data[[i for i in range(data.shape[0]) if i != target_feature]].T        \n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return None\n",
    "\n",
    "    @property\n",
    "    def in_dim(self):\n",
    "        return None\n",
    "    \n",
    "target_feature = 'tlak vzduchu'\n",
    "train_dataset = MeteoDataset(np.concatenate([mosnov, kosetice, pribyslav], axis=1), features.index(target_feature))\n",
    "valid_dataset = MeteoDataset(ruzyne, features.index(target_feature))\n",
    "test_dataset = MeteoDataset(ruzyne, features.index(target_feature))\n",
    "print(valid_dataset.xs.shape, valid_dataset.ts.shape)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=128, shuffle=False, drop_last=False)\n",
    "print(len(valid_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zde je definována funkce pro evaluaci modelu.\n",
    "Budete ji používat, ale implementovat v ní nic nemusíte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    total_squared_error = 0.0\n",
    "    nb_datos = 0\n",
    "    with torch.no_grad():\n",
    "        for X, t in data_loader:\n",
    "            y = model(X)\n",
    "            total_squared_error += torch.nn.functional.mse_loss(y, t, reduction='sum')\n",
    "            nb_datos += len(t)\n",
    "        \n",
    "    return total_squared_error / nb_datos\n",
    "\n",
    "evaluate(LinearRegression(train_dataset.in_dim), valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nad trénovacím dataset vytvořte `DataLoader`, který bude vytvářet minibatche o velikosti 32 příkladů.\n",
    "Poté z něj vytvořte nekonečný proud dat.\n",
    "Můžete k tomu naimplementovat vlastní cyklící iterátor nebo použít vhodnou funkci z `itertools`.\n",
    "\n",
    "Dále naimplementujte trénovací smyčku ve funkci `train()`, která přijímá:\n",
    "* `model` -- referenci na model, jenž má být natrénován\n",
    "* `train_stream` -- iterátor přes trénovací batche\n",
    "* `optimizer` -- instanci optimalizátoru,  který bude využit pro trénování\n",
    "* `nb_updates` -- počet trénovacích kroků, jež mají být provedeny\n",
    "* `eval_period` -- po kolika krocích se má vyhodnocovat model na validačních datech\n",
    "* `valid_loader` -- iterable s validačními daty\n",
    "\n",
    "Funkce nechť používá `torch.nn.functional.mse_loss()` jako loss.\n",
    "Vracejte průběh validační loss spolu s pořadovými čísly kroků, kdy došlo k měření, tedy jako seznam dvojic `[(i_1, loss_1), ...]`.\n",
    "`model` trénujte přímo.\n",
    "\n",
    "Zbytek buňky vyzkouší trénování pro několik různých learning rate.\n",
    "Vzhledem k jednoduchosti úlohy jsou to learning rate gigantické oproti prakticky používaným."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = None\n",
    "\n",
    "train_stream = None\n",
    "\n",
    "def train(model, train_stream, optimizer, nb_updates, eval_period, valid_loader):\n",
    "    valid_progress = []\n",
    "    \n",
    "    model.train()\n",
    "    for i in range(nb_updates):\n",
    "        pass\n",
    "\n",
    "    return valid_progress\n",
    "\n",
    "def lr_progress(lr):\n",
    "    linear_predictor = LinearRegression(train_dataset.in_dim)\n",
    "    optimizer = torch.optim.Adam(linear_predictor.parameters(), lr)\n",
    "    progress = train(linear_predictor, train_stream, optimizer, 250, 10, valid_loader)\n",
    "    print(lr, evaluate(linear_predictor, valid_loader))\n",
    "    return progress\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for lr in [3e+1, 1e+1, 1e+0, 3e-1]:\n",
    "    progress = lr_progress(lr)\n",
    "    plt.plot([item[0] for item in progress], [item[1] for item in progress], label=f\"{lr:.1e}\")\n",
    "plt.legend()\n",
    "plt.ylim(0, 30000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konečně naimplementujte jednoduchou neuronovou síť, která bude schopná regrese.\n",
    "Při konstrukci nechť přijímá:\n",
    "* rozměr vstupu\n",
    "* počet skrytých vstev\n",
    "* šířku každé skryté vrstvy\n",
    "* instanci nelinearity, která má být aplikována v každé skryté vrstvé\n",
    "\n",
    "Při dopředném průchodu nechť se uplatní všechny vrstvy, nezapomeňte opět redukovat výstup na [N].\n",
    "Nejspíš se Vám bude hodit `torch.nn.Sequential`.\n",
    "\n",
    "Zbytek buňky vyzkouší několik různých konfigurací.\n",
    "Pravděpodobně uvidíte ilustraci faktu, že v rozporu s častou reportovací praxí není počet parametrů nutně tím nejzásadnějším číslem pro odhad síly modelu, tím může být prostě šířka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocalMeteoModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, nb_layers, layer_width, nonlinearity):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        assert nb_layers >= 1\n",
    "\n",
    "        pass\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return None\n",
    "    \n",
    "\n",
    "def depth_progress(depth, width):\n",
    "    nn_predictor = LocalMeteoModel(train_dataset.in_dim, depth, width, torch.nn.Tanh())\n",
    "    optimizer = torch.optim.SGD(nn_predictor.parameters(), 3e-5)\n",
    "    progress = train(nn_predictor, train_stream, optimizer, 1500, 100, valid_loader)\n",
    "    print(f\"Depth {depth}, width {width}: {evaluate(nn_predictor, valid_loader):.2f}\")\n",
    "    return progress\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for depth, width in [(1, 16), (4, 16), (1, 64), (4, 64)]:\n",
    "    progress = depth_progress(depth, width)\n",
    "    plt.plot([item[0] for item in progress], [item[1] for item in progress], label=f\"{depth}x{width}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gratulujeme ke zvládnutí projektu! Při odevzdání nezapomeňte soubory pojmenovat podle vedoucího týmu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
